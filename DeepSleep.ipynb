{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "random.seed(7493)\n",
    "np.random.seed(7493)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(data, size):\n",
    "    for item in itertools.cycle(data):\n",
    "        perm = np.random.permutation(item['Y'].shape[0])\n",
    "        for i in np.arange(0, item['Y'].shape[0], size):\n",
    "#             print 'i:', i, 'shape:', item['Y'].shape[0], 'size:', size\n",
    "            yield (item['X'][perm[i:i + size]], item['Y'][perm[i:i + size]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unfold(data):\n",
    "    x, y = np.array(data[0]['X']), np.array(data[0]['Y'])\n",
    "    for item in data[1:]:\n",
    "        x = np.concatenate((x, item['X'])); y = np.concatenate((y, item['Y']))\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_samples(data):\n",
    "    return np.sum([item['Y'].shape[0] for item in data])\n",
    "\n",
    "def count_steps(data, batch_size):\n",
    "    return int(np.sum([item['Y'].shape[0]/batch_size for item in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # Load all npz files from path\n",
    "    return np.array([np.load(np_name) for np_name in glob.glob(os.path.join(path, '*.np[yz]'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data, split=0.1):\n",
    "    \"\"\"\n",
    "    Split data into train and test set\n",
    "    \"\"\"\n",
    "    i = int(len(data)*split)\n",
    "    perm = np.random.permutation(len(data)) # permute data\n",
    "    return data[perm[i:]], data[perm[0:i]] # return training, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(n_classes, y_true, y_pred):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = metrics.roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = metrics.roc_curve(y_true.ravel(), y_pred.ravel())\n",
    "    roc_auc[\"micro\"] = metrics.auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[\"micro\"])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    roc_score = metrics.roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    #print \"Loss: {} Accuracy: {}%\".format(loss_and_metrics[0],loss_and_metrics[1] * 100)\n",
    "    print \"ROC AUC Score: \", roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(lr=1e-5, batch_size=64, decay=0, m=0.5, ridge=2e-4, init='he_normal'):\n",
    "    adam = Adam(lr=lr, decay=decay)\n",
    "    bias_init = Constant(value=0.1)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(25, 50, padding='valid', input_shape=(15000, 3), kernel_initializer=init, bias_initializer=bias_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv1D(25, 50, padding='valid', kernel_initializer=init, bias_initializer=bias_init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling1D())\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(1024, kernel_initializer=init, bias_initializer=bias_init, kernel_regularizer=l2(ridge)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(5, kernel_initializer=init, bias_initializer=bias_init, kernel_regularizer=l2(ridge)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(data, k_folds=9, batch_size=192, epochs=100, lr=1e-5, decay=0.9, m=0.5, ridge=2e-4):\n",
    "    model = build_model(lr=lr, batch_size=batch_size, decay=decay, m=m, ridge=ridge)\n",
    "    model.summary()\n",
    "    fold_size = int(math.ceil(len(data)/k_folds))\n",
    "    earlyStopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "    \n",
    "    for k in range(k_folds):\n",
    "        i = int(k * fold_size)\n",
    "        val = data[i:i+fold_size]\n",
    "        train = np.concatenate((data[:i],data[i+fold_size:]))\n",
    "#         steps_per_epoch = int(count_samples(train) / batch_size)\n",
    "        steps_per_epoch = count_steps(train, batch_size)\n",
    "        print 'Fold:',(k+1),'Samples:',count_samples(train),'Epochs:',epochs,'Steps:',steps_per_epoch\n",
    "        \n",
    "        name = 'f' + str(k+1) + '-e' + str(epochs) + '-lr' + str(lr)+ '-dcy' + str(decay) + '-mntm' + str(m) + '-reg' + str(ridge)\n",
    "        filepath = './history/DS_' + name + '_{epoch:03d}-{val_acc:.2f}.h5'\n",
    "        checkpointer = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "        \n",
    "        model.fit_generator(next_batch(train, batch_size), steps_per_epoch, epochs=epochs, verbose=2,\n",
    "                            validation_data=unfold(val),\n",
    "                            callbacks=[checkpointer, earlyStopper])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, test, batch_size=192):\n",
    "    # Test model on test set\n",
    "    test_x, y_true = unfold(test)\n",
    "    loss_and_metrics = model.evaluate(test_x, y_true, batch_size=batch_size, verbose=1)\n",
    "    y_pred = model.predict(test_x, batch_size=batch_size, verbose=1)\n",
    "    \n",
    "    y_true_class = np.argmax(y_true, axis=1)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "    conf_mat = metrics.confusion_matrix(y_true_class, y_pred_class)\n",
    "    \n",
    "    print \"Test Loss and accuracy: \", loss_and_metrics\n",
    "    plot_roc_curve(5, y_true, y_pred)\n",
    "    plot_confusion_matrix(conf_mat, classes=['S1', 'S2', 'S3', 'A', 'R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup(data_dir, k_folds=9, batch_size=192, epochs=100, lr=1e-5, decay=0.9, m=0.5, ridge=2e-4):\n",
    "    data = load_data(data_dir)\n",
    "    data, test = split_data(data)\n",
    "    model = train_model(data, k_folds=k_folds, batch_size=batch_size, epochs=epochs, lr=lr, decay=decay, m=m, ridge=ridge)\n",
    "    test_model(model, test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 14951, 25)         3775      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14951, 25)         100       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14951, 25)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 14902, 25)         31275     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14902, 25)         100       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14902, 25)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 7451, 25)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 186275)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              190746624 \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 5125      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 190,791,095\n",
      "Trainable params: 190,788,947\n",
      "Non-trainable params: 2,148\n",
      "_________________________________________________________________\n",
      "Fold: 1 Samples: 28530 Epochs: 100 Steps: 140\n",
      "Epoch 1/100\n",
      "293s - loss: 1.7438 - acc: 0.5494 - val_loss: 1.9202 - val_acc: 0.3723\n",
      "Epoch 2/100\n",
      "228s - loss: 1.5530 - acc: 0.6073 - val_loss: 1.9229 - val_acc: 0.4484\n",
      "Epoch 3/100\n",
      "231s - loss: 1.5495 - acc: 0.6094 - val_loss: 2.0330 - val_acc: 0.4751\n",
      "Epoch 4/100\n",
      "232s - loss: 1.5453 - acc: 0.6132 - val_loss: 2.1477 - val_acc: 0.4657\n",
      "Epoch 5/100\n",
      "232s - loss: 1.5259 - acc: 0.6183 - val_loss: 2.2160 - val_acc: 0.4610\n",
      "Epoch 6/100\n",
      "228s - loss: 1.5140 - acc: 0.6250 - val_loss: 2.2554 - val_acc: 0.4573\n",
      "Epoch 7/100\n",
      "232s - loss: 1.4634 - acc: 0.6328 - val_loss: 2.3420 - val_acc: 0.4444\n",
      "Epoch 8/100\n",
      "232s - loss: 1.5073 - acc: 0.6302 - val_loss: 2.3525 - val_acc: 0.4437\n",
      "Epoch 9/100\n",
      "231s - loss: 1.4772 - acc: 0.6418 - val_loss: 2.2988 - val_acc: 0.4528\n",
      "Epoch 10/100\n",
      "229s - loss: 1.5063 - acc: 0.6301 - val_loss: 2.3254 - val_acc: 0.4512\n",
      "Epoch 11/100\n",
      "227s - loss: 1.4416 - acc: 0.6520 - val_loss: 2.2666 - val_acc: 0.4624\n",
      "Epoch 12/100\n",
      "228s - loss: 1.4371 - acc: 0.6509 - val_loss: 2.2461 - val_acc: 0.4685\n",
      "Epoch 00011: early stopping\n",
      "Fold: 2 Samples: 29293 Epochs: 100 Steps: 145\n",
      "Epoch 1/100\n",
      "276s - loss: 1.5191 - acc: 0.6232 - val_loss: 1.3101 - val_acc: 0.7121\n",
      "Epoch 2/100\n",
      "240s - loss: 1.4849 - acc: 0.6279 - val_loss: 1.3119 - val_acc: 0.7147\n",
      "Epoch 3/100\n",
      "268s - loss: 1.5156 - acc: 0.6205 - val_loss: 1.2980 - val_acc: 0.7175\n",
      "Epoch 4/100\n",
      "280s - loss: 1.5340 - acc: 0.6154 - val_loss: 1.2662 - val_acc: 0.7252\n",
      "Epoch 5/100\n",
      "242s - loss: 1.5297 - acc: 0.6161 - val_loss: 1.2678 - val_acc: 0.7249\n",
      "Epoch 6/100\n",
      "264s - loss: 1.5068 - acc: 0.6217 - val_loss: 1.2582 - val_acc: 0.7255\n",
      "Epoch 7/100\n",
      "244s - loss: 1.4864 - acc: 0.6235 - val_loss: 1.2736 - val_acc: 0.7235\n",
      "Epoch 8/100\n",
      "244s - loss: 1.5332 - acc: 0.6183 - val_loss: 1.2868 - val_acc: 0.7209\n",
      "Epoch 9/100\n",
      "264s - loss: 1.4848 - acc: 0.6383 - val_loss: 1.2545 - val_acc: 0.7289\n",
      "Epoch 10/100\n",
      "239s - loss: 1.4806 - acc: 0.6363 - val_loss: 1.3122 - val_acc: 0.7115\n",
      "Epoch 11/100\n",
      "239s - loss: 1.4911 - acc: 0.6336 - val_loss: 1.3104 - val_acc: 0.7129\n",
      "Epoch 12/100\n",
      "241s - loss: 1.4684 - acc: 0.6343 - val_loss: 1.3141 - val_acc: 0.7132\n",
      "Epoch 13/100\n",
      "243s - loss: 1.4973 - acc: 0.6298 - val_loss: 1.2999 - val_acc: 0.7161\n",
      "Epoch 14/100\n",
      "243s - loss: 1.5154 - acc: 0.6251 - val_loss: 1.2695 - val_acc: 0.7223\n",
      "Epoch 15/100\n",
      "241s - loss: 1.5075 - acc: 0.6233 - val_loss: 1.2622 - val_acc: 0.7246\n",
      "Epoch 16/100\n",
      "242s - loss: 1.4969 - acc: 0.6292 - val_loss: 1.2551 - val_acc: 0.7246\n",
      "Epoch 17/100\n",
      "244s - loss: 1.4753 - acc: 0.6302 - val_loss: 1.2705 - val_acc: 0.7218\n",
      "Epoch 18/100\n",
      "246s - loss: 1.5159 - acc: 0.6245 - val_loss: 1.2933 - val_acc: 0.7212\n",
      "Epoch 19/100\n",
      "240s - loss: 1.4636 - acc: 0.6454 - val_loss: 1.2570 - val_acc: 0.7286\n",
      "Epoch 20/100\n",
      "239s - loss: 1.4719 - acc: 0.6396 - val_loss: 1.3020 - val_acc: 0.7149\n",
      "Epoch 00019: early stopping\n",
      "Fold: 3 Samples: 29380 Epochs: 100 Steps: 145\n",
      "Epoch 1/100\n",
      "277s - loss: 1.4496 - acc: 0.6536 - val_loss: 1.2406 - val_acc: 0.6878\n",
      "Epoch 2/100\n",
      "241s - loss: 1.4259 - acc: 0.6578 - val_loss: 1.2461 - val_acc: 0.6899\n",
      "Epoch 3/100\n",
      "244s - loss: 1.4585 - acc: 0.6481 - val_loss: 1.2414 - val_acc: 0.6896\n",
      "Epoch 4/100\n",
      "269s - loss: 1.4644 - acc: 0.6463 - val_loss: 1.2374 - val_acc: 0.6907\n",
      "Epoch 5/100\n",
      "243s - loss: 1.4690 - acc: 0.6437 - val_loss: 1.2404 - val_acc: 0.6937\n",
      "Epoch 6/100\n",
      "242s - loss: 1.4552 - acc: 0.6483 - val_loss: 1.2388 - val_acc: 0.6934\n",
      "Epoch 7/100\n",
      "272s - loss: 1.4267 - acc: 0.6504 - val_loss: 1.2346 - val_acc: 0.6934\n",
      "Epoch 8/100\n",
      "244s - loss: 1.4697 - acc: 0.6447 - val_loss: 1.2440 - val_acc: 0.6939\n",
      "Epoch 9/100\n",
      "240s - loss: 1.4623 - acc: 0.6472 - val_loss: 1.2429 - val_acc: 0.6963\n",
      "Epoch 10/100\n",
      "241s - loss: 1.4307 - acc: 0.6590 - val_loss: 1.2360 - val_acc: 0.6896\n",
      "Epoch 11/100\n",
      "241s - loss: 1.4417 - acc: 0.6595 - val_loss: 1.2375 - val_acc: 0.6901\n",
      "Epoch 12/100\n",
      "242s - loss: 1.4190 - acc: 0.6607 - val_loss: 1.2443 - val_acc: 0.6925\n",
      "Epoch 13/100\n",
      "245s - loss: 1.4413 - acc: 0.6531 - val_loss: 1.2395 - val_acc: 0.6916\n",
      "Epoch 14/100\n",
      "244s - loss: 1.4568 - acc: 0.6542 - val_loss: 1.2364 - val_acc: 0.6931\n",
      "Epoch 15/100\n",
      "242s - loss: 1.4599 - acc: 0.6465 - val_loss: 1.2373 - val_acc: 0.6942\n",
      "Epoch 16/100\n",
      "243s - loss: 1.4458 - acc: 0.6512 - val_loss: 1.2368 - val_acc: 0.6948\n",
      "Epoch 17/100\n",
      "270s - loss: 1.4158 - acc: 0.6546 - val_loss: 1.2326 - val_acc: 0.6939\n",
      "Epoch 18/100\n",
      "244s - loss: 1.4640 - acc: 0.6446 - val_loss: 1.2404 - val_acc: 0.6969\n",
      "Epoch 19/100\n",
      "242s - loss: 1.4582 - acc: 0.6508 - val_loss: 1.2405 - val_acc: 0.6980\n",
      "Epoch 20/100\n",
      "240s - loss: 1.4262 - acc: 0.6621 - val_loss: 1.2337 - val_acc: 0.6913\n",
      "Epoch 21/100\n",
      "241s - loss: 1.4374 - acc: 0.6582 - val_loss: 1.2345 - val_acc: 0.6910\n",
      "Epoch 22/100\n",
      "242s - loss: 1.4064 - acc: 0.6644 - val_loss: 1.2429 - val_acc: 0.6937\n",
      "Epoch 23/100\n",
      "244s - loss: 1.4344 - acc: 0.6535 - val_loss: 1.2370 - val_acc: 0.6939\n",
      "Epoch 24/100\n",
      "244s - loss: 1.4537 - acc: 0.6539 - val_loss: 1.2351 - val_acc: 0.6937\n",
      "Epoch 25/100\n",
      "242s - loss: 1.4562 - acc: 0.6488 - val_loss: 1.2351 - val_acc: 0.6939\n",
      "Epoch 26/100\n",
      "242s - loss: 1.4374 - acc: 0.6531 - val_loss: 1.2341 - val_acc: 0.6948\n",
      "Epoch 27/100\n",
      "271s - loss: 1.4177 - acc: 0.6571 - val_loss: 1.2300 - val_acc: 0.6939\n",
      "Epoch 28/100\n",
      "244s - loss: 1.4513 - acc: 0.6485 - val_loss: 1.2381 - val_acc: 0.6975\n",
      "Epoch 29/100\n",
      "242s - loss: 1.4544 - acc: 0.6539 - val_loss: 1.2401 - val_acc: 0.6983\n",
      "Epoch 30/100\n",
      "240s - loss: 1.4118 - acc: 0.6686 - val_loss: 1.2314 - val_acc: 0.6931\n",
      "Epoch 31/100\n",
      "241s - loss: 1.4289 - acc: 0.6642 - val_loss: 1.2325 - val_acc: 0.6916\n",
      "Epoch 32/100\n",
      "242s - loss: 1.4039 - acc: 0.6641 - val_loss: 1.2410 - val_acc: 0.6954\n",
      "Epoch 33/100\n",
      "245s - loss: 1.4331 - acc: 0.6567 - val_loss: 1.2361 - val_acc: 0.6954\n",
      "Epoch 34/100\n",
      "244s - loss: 1.4451 - acc: 0.6547 - val_loss: 1.2342 - val_acc: 0.6963\n",
      "Epoch 35/100\n",
      "242s - loss: 1.4455 - acc: 0.6508 - val_loss: 1.2342 - val_acc: 0.6960\n",
      "Epoch 36/100\n",
      "243s - loss: 1.4353 - acc: 0.6559 - val_loss: 1.2325 - val_acc: 0.6960\n",
      "Epoch 37/100\n",
      "271s - loss: 1.4144 - acc: 0.6577 - val_loss: 1.2285 - val_acc: 0.6934\n",
      "Epoch 38/100\n",
      "244s - loss: 1.4524 - acc: 0.6504 - val_loss: 1.2375 - val_acc: 0.6986\n",
      "Epoch 39/100\n",
      "242s - loss: 1.4483 - acc: 0.6555 - val_loss: 1.2403 - val_acc: 0.7004\n",
      "Epoch 40/100\n",
      "240s - loss: 1.4124 - acc: 0.6661 - val_loss: 1.2306 - val_acc: 0.6931\n",
      "Epoch 41/100\n",
      "247s - loss: 1.4345 - acc: 0.6621 - val_loss: 1.2301 - val_acc: 0.6916\n",
      "Epoch 42/100\n",
      "239s - loss: 1.3882 - acc: 0.6710 - val_loss: 1.2404 - val_acc: 0.6977\n",
      "Epoch 43/100\n",
      "244s - loss: 1.4212 - acc: 0.6584 - val_loss: 1.2355 - val_acc: 0.6957\n",
      "Epoch 44/100\n",
      "244s - loss: 1.4454 - acc: 0.6544 - val_loss: 1.2339 - val_acc: 0.6972\n",
      "Epoch 45/100\n",
      "242s - loss: 1.4538 - acc: 0.6476 - val_loss: 1.2312 - val_acc: 0.6966\n",
      "Epoch 46/100\n",
      "241s - loss: 1.4321 - acc: 0.6567 - val_loss: 1.2313 - val_acc: 0.6977\n",
      "Epoch 47/100\n",
      "277s - loss: 1.4085 - acc: 0.6618 - val_loss: 1.2269 - val_acc: 0.6954\n",
      "Epoch 48/100\n",
      "244s - loss: 1.4443 - acc: 0.6518 - val_loss: 1.2357 - val_acc: 0.6995\n",
      "Epoch 49/100\n",
      "242s - loss: 1.4617 - acc: 0.6492 - val_loss: 1.2386 - val_acc: 0.7010\n",
      "Epoch 50/100\n",
      "238s - loss: 1.4084 - acc: 0.6716 - val_loss: 1.2304 - val_acc: 0.6969\n",
      "Epoch 51/100\n",
      "240s - loss: 1.4293 - acc: 0.6634 - val_loss: 1.2292 - val_acc: 0.6934\n",
      "Epoch 52/100\n",
      "242s - loss: 1.3907 - acc: 0.6686 - val_loss: 1.2391 - val_acc: 0.6980\n",
      "Epoch 53/100\n",
      "244s - loss: 1.4232 - acc: 0.6617 - val_loss: 1.2348 - val_acc: 0.6969\n",
      "Epoch 54/100\n",
      "244s - loss: 1.4421 - acc: 0.6584 - val_loss: 1.2329 - val_acc: 0.6983\n",
      "Epoch 55/100\n",
      "242s - loss: 1.4465 - acc: 0.6525 - val_loss: 1.2308 - val_acc: 0.6977\n",
      "Epoch 56/100\n",
      "242s - loss: 1.4273 - acc: 0.6561 - val_loss: 1.2314 - val_acc: 0.6986\n",
      "Epoch 57/100\n",
      "268s - loss: 1.4091 - acc: 0.6605 - val_loss: 1.2268 - val_acc: 0.6969\n",
      "Epoch 58/100\n",
      "244s - loss: 1.4441 - acc: 0.6521 - val_loss: 1.2348 - val_acc: 0.7007\n",
      "Epoch 59/100\n",
      "242s - loss: 1.4572 - acc: 0.6540 - val_loss: 1.2397 - val_acc: 0.7001\n",
      "Epoch 60/100\n",
      "238s - loss: 1.4023 - acc: 0.6736 - val_loss: 1.2302 - val_acc: 0.6986\n",
      "Epoch 61/100\n",
      "241s - loss: 1.4252 - acc: 0.6681 - val_loss: 1.2280 - val_acc: 0.6931\n",
      "Epoch 62/100\n",
      "241s - loss: 1.3891 - acc: 0.6707 - val_loss: 1.2389 - val_acc: 0.6975\n",
      "Epoch 63/100\n",
      "244s - loss: 1.4170 - acc: 0.6630 - val_loss: 1.2336 - val_acc: 0.6986\n",
      "Epoch 64/100\n",
      "243s - loss: 1.4311 - acc: 0.6596 - val_loss: 1.2322 - val_acc: 0.6995\n",
      "Epoch 65/100\n",
      "243s - loss: 1.4401 - acc: 0.6552 - val_loss: 1.2292 - val_acc: 0.6972\n",
      "Epoch 66/100\n",
      "241s - loss: 1.4211 - acc: 0.6597 - val_loss: 1.2301 - val_acc: 0.6977\n",
      "Epoch 67/100\n",
      "270s - loss: 1.4157 - acc: 0.6628 - val_loss: 1.2263 - val_acc: 0.6983\n",
      "Epoch 68/100\n",
      "245s - loss: 1.4278 - acc: 0.6581 - val_loss: 1.2333 - val_acc: 0.7015\n",
      "Epoch 69/100\n",
      "243s - loss: 1.4527 - acc: 0.6524 - val_loss: 1.2393 - val_acc: 0.7007\n",
      "Epoch 70/100\n",
      "239s - loss: 1.3901 - acc: 0.6759 - val_loss: 1.2300 - val_acc: 0.6989\n",
      "Epoch 71/100\n",
      "241s - loss: 1.4177 - acc: 0.6676 - val_loss: 1.2273 - val_acc: 0.6939\n",
      "Epoch 72/100\n",
      "242s - loss: 1.3857 - acc: 0.6729 - val_loss: 1.2389 - val_acc: 0.6975\n",
      "Epoch 73/100\n",
      "244s - loss: 1.4098 - acc: 0.6643 - val_loss: 1.2332 - val_acc: 0.6986\n",
      "Epoch 74/100\n",
      "245s - loss: 1.4237 - acc: 0.6614 - val_loss: 1.2311 - val_acc: 0.6992\n",
      "Epoch 75/100\n",
      "243s - loss: 1.4447 - acc: 0.6543 - val_loss: 1.2270 - val_acc: 0.6977\n",
      "Epoch 76/100\n",
      "242s - loss: 1.4133 - acc: 0.6617 - val_loss: 1.2304 - val_acc: 0.6989\n",
      "Epoch 77/100\n",
      "245s - loss: 1.4076 - acc: 0.6634 - val_loss: 1.2269 - val_acc: 0.6983\n",
      "Epoch 78/100\n",
      "245s - loss: 1.4222 - acc: 0.6557 - val_loss: 1.2314 - val_acc: 0.7015\n",
      "Epoch 00077: early stopping\n",
      "Fold: 4 Samples: 29564 Epochs: 100 Steps: 146\n",
      "Epoch 1/100\n",
      "278s - loss: 1.3962 - acc: 0.6597 - val_loss: 1.7486 - val_acc: 0.6605\n",
      "Epoch 2/100\n",
      "244s - loss: 1.3513 - acc: 0.6691 - val_loss: 1.7738 - val_acc: 0.6596\n",
      "Epoch 3/100\n",
      "247s - loss: 1.3962 - acc: 0.6555 - val_loss: 1.7587 - val_acc: 0.6589\n",
      "Epoch 4/100\n",
      "274s - loss: 1.4192 - acc: 0.6518 - val_loss: 1.7139 - val_acc: 0.6645\n",
      "Epoch 5/100\n",
      "245s - loss: 1.4096 - acc: 0.6499 - val_loss: 1.7255 - val_acc: 0.6639\n",
      "Epoch 6/100\n",
      "243s - loss: 1.3961 - acc: 0.6529 - val_loss: 1.7165 - val_acc: 0.6642\n",
      "Epoch 7/100\n",
      "274s - loss: 1.4096 - acc: 0.6566 - val_loss: 1.6873 - val_acc: 0.6679\n",
      "Epoch 8/100\n",
      "270s - loss: 1.3963 - acc: 0.6611 - val_loss: 1.6847 - val_acc: 0.6691\n",
      "Epoch 9/100\n",
      "267s - loss: 1.4025 - acc: 0.6550 - val_loss: 1.6657 - val_acc: 0.6707\n",
      "Epoch 10/100\n",
      "242s - loss: 1.3737 - acc: 0.6662 - val_loss: 1.7985 - val_acc: 0.6518\n",
      "Epoch 11/100\n",
      "242s - loss: 1.3859 - acc: 0.6658 - val_loss: 1.8038 - val_acc: 0.6509\n",
      "Epoch 12/100\n",
      "244s - loss: 1.3536 - acc: 0.6667 - val_loss: 1.7967 - val_acc: 0.6559\n",
      "Epoch 13/100\n",
      "246s - loss: 1.3929 - acc: 0.6564 - val_loss: 1.7821 - val_acc: 0.6580\n",
      "Epoch 14/100\n",
      "246s - loss: 1.3974 - acc: 0.6582 - val_loss: 1.7190 - val_acc: 0.6630\n",
      "Epoch 15/100\n",
      "244s - loss: 1.4080 - acc: 0.6479 - val_loss: 1.7201 - val_acc: 0.6645\n",
      "Epoch 16/100\n",
      "244s - loss: 1.3944 - acc: 0.6551 - val_loss: 1.7108 - val_acc: 0.6657\n",
      "Epoch 17/100\n",
      "247s - loss: 1.4051 - acc: 0.6530 - val_loss: 1.7015 - val_acc: 0.6664\n",
      "Epoch 18/100\n",
      "245s - loss: 1.3867 - acc: 0.6627 - val_loss: 1.6747 - val_acc: 0.6701\n",
      "Epoch 19/100\n",
      "244s - loss: 1.4083 - acc: 0.6514 - val_loss: 1.6700 - val_acc: 0.6704\n",
      "Epoch 20/100\n",
      "241s - loss: 1.3660 - acc: 0.6693 - val_loss: 1.7506 - val_acc: 0.6617\n",
      "Epoch 00019: early stopping\n",
      "Fold: 5 Samples: 29196 Epochs: 100 Steps: 144\n",
      "Epoch 1/100\n",
      "273s - loss: 1.4201 - acc: 0.6620 - val_loss: 1.3420 - val_acc: 0.6921\n",
      "Epoch 2/100\n",
      "263s - loss: 1.3787 - acc: 0.6653 - val_loss: 1.3337 - val_acc: 0.6968\n",
      "Epoch 3/100\n",
      "265s - loss: 1.4242 - acc: 0.6516 - val_loss: 1.3206 - val_acc: 0.6974\n",
      "Epoch 4/100\n",
      "266s - loss: 1.4292 - acc: 0.6514 - val_loss: 1.2958 - val_acc: 0.7026\n",
      "Epoch 5/100\n",
      "265s - loss: 1.4436 - acc: 0.6461 - val_loss: 1.2953 - val_acc: 0.7015\n",
      "Epoch 6/100\n",
      "242s - loss: 1.3958 - acc: 0.6572 - val_loss: 1.3102 - val_acc: 0.7024\n",
      "Epoch 7/100\n",
      "268s - loss: 1.4289 - acc: 0.6531 - val_loss: 1.2912 - val_acc: 0.7054\n",
      "Epoch 8/100\n",
      "241s - loss: 1.4267 - acc: 0.6557 - val_loss: 1.3009 - val_acc: 0.7054\n",
      "Epoch 9/100\n",
      "262s - loss: 1.4288 - acc: 0.6534 - val_loss: 1.2857 - val_acc: 0.7093\n",
      "Epoch 10/100\n",
      "239s - loss: 1.3999 - acc: 0.6649 - val_loss: 1.3696 - val_acc: 0.6838\n",
      "Epoch 11/100\n",
      "237s - loss: 1.4126 - acc: 0.6610 - val_loss: 1.3480 - val_acc: 0.6910\n",
      "Epoch 12/100\n",
      "240s - loss: 1.3836 - acc: 0.6639 - val_loss: 1.3384 - val_acc: 0.6960\n",
      "Epoch 13/100\n",
      "242s - loss: 1.4163 - acc: 0.6544 - val_loss: 1.3213 - val_acc: 0.6982\n",
      "Epoch 14/100\n",
      "242s - loss: 1.4307 - acc: 0.6529 - val_loss: 1.2990 - val_acc: 0.7021\n",
      "Epoch 15/100\n",
      "240s - loss: 1.4351 - acc: 0.6486 - val_loss: 1.2960 - val_acc: 0.7021\n",
      "Epoch 16/100\n",
      "242s - loss: 1.3934 - acc: 0.6530 - val_loss: 1.3106 - val_acc: 0.7029\n",
      "Epoch 17/100\n",
      "242s - loss: 1.4356 - acc: 0.6534 - val_loss: 1.2912 - val_acc: 0.7062\n",
      "Epoch 18/100\n",
      "241s - loss: 1.4214 - acc: 0.6569 - val_loss: 1.3040 - val_acc: 0.7065\n",
      "Epoch 19/100\n",
      "238s - loss: 1.4196 - acc: 0.6566 - val_loss: 1.2857 - val_acc: 0.7090\n",
      "Epoch 20/100\n",
      "240s - loss: 1.4060 - acc: 0.6657 - val_loss: 1.3723 - val_acc: 0.6832\n",
      "Epoch 00019: early stopping\n",
      "Fold: 6 Samples: 29036 Epochs: 100 Steps: 144\n",
      "Epoch 1/100\n",
      "272s - loss: 1.4236 - acc: 0.6582 - val_loss: 1.2995 - val_acc: 0.6988\n",
      "Epoch 2/100\n",
      "237s - loss: 1.3941 - acc: 0.6598 - val_loss: 1.3014 - val_acc: 0.6985\n",
      "Epoch 3/100\n",
      "265s - loss: 1.4258 - acc: 0.6537 - val_loss: 1.2850 - val_acc: 0.7036\n",
      "Epoch 4/100\n",
      "265s - loss: 1.4337 - acc: 0.6533 - val_loss: 1.2670 - val_acc: 0.7049\n",
      "Epoch 5/100\n",
      "264s - loss: 1.4370 - acc: 0.6478 - val_loss: 1.2626 - val_acc: 0.7060\n",
      "Epoch 6/100\n",
      "243s - loss: 1.4049 - acc: 0.6519 - val_loss: 1.2741 - val_acc: 0.7070\n",
      "Epoch 7/100\n",
      "243s - loss: 1.4483 - acc: 0.6508 - val_loss: 1.2675 - val_acc: 0.7057\n",
      "Epoch 8/100\n",
      "242s - loss: 1.4316 - acc: 0.6534 - val_loss: 1.2823 - val_acc: 0.7060\n",
      "Epoch 9/100\n",
      "238s - loss: 1.4368 - acc: 0.6526 - val_loss: 1.2698 - val_acc: 0.7086\n",
      "Epoch 10/100\n",
      "239s - loss: 1.4051 - acc: 0.6641 - val_loss: 1.3132 - val_acc: 0.6940\n",
      "Epoch 11/100\n",
      "237s - loss: 1.4149 - acc: 0.6579 - val_loss: 1.3035 - val_acc: 0.6983\n",
      "Epoch 12/100\n",
      "239s - loss: 1.3929 - acc: 0.6588 - val_loss: 1.2993 - val_acc: 0.6993\n",
      "Epoch 13/100\n",
      "241s - loss: 1.4315 - acc: 0.6494 - val_loss: 1.2857 - val_acc: 0.7028\n",
      "Epoch 14/100\n",
      "241s - loss: 1.4368 - acc: 0.6495 - val_loss: 1.2664 - val_acc: 0.7052\n",
      "Epoch 15/100\n",
      "241s - loss: 1.4438 - acc: 0.6476 - val_loss: 1.2671 - val_acc: 0.7041\n",
      "Epoch 16/100\n",
      "244s - loss: 1.4045 - acc: 0.6529 - val_loss: 1.2746 - val_acc: 0.7068\n",
      "Epoch 00015: early stopping\n",
      "Fold: 7 Samples: 29419 Epochs: 100 Steps: 146\n",
      "Epoch 1/100\n",
      "278s - loss: 1.4107 - acc: 0.6632 - val_loss: 1.1134 - val_acc: 0.7232\n",
      "Epoch 2/100\n",
      "269s - loss: 1.3829 - acc: 0.6666 - val_loss: 1.1133 - val_acc: 0.7253\n",
      "Epoch 3/100\n",
      "272s - loss: 1.4269 - acc: 0.6584 - val_loss: 1.1105 - val_acc: 0.7215\n",
      "Epoch 4/100\n",
      "244s - loss: 1.4297 - acc: 0.6538 - val_loss: 1.1110 - val_acc: 0.7229\n",
      "Epoch 5/100\n",
      "271s - loss: 1.4259 - acc: 0.6578 - val_loss: 1.1090 - val_acc: 0.7229\n",
      "Epoch 6/100\n",
      "272s - loss: 1.3967 - acc: 0.6603 - val_loss: 1.1070 - val_acc: 0.7209\n",
      "Epoch 7/100\n",
      "246s - loss: 1.4303 - acc: 0.6584 - val_loss: 1.1088 - val_acc: 0.7253\n",
      "Epoch 8/100\n",
      "245s - loss: 1.4201 - acc: 0.6637 - val_loss: 1.1127 - val_acc: 0.7262\n",
      "Epoch 9/100\n",
      "243s - loss: 1.4272 - acc: 0.6576 - val_loss: 1.1100 - val_acc: 0.7271\n",
      "Epoch 10/100\n",
      "242s - loss: 1.3949 - acc: 0.6701 - val_loss: 1.1159 - val_acc: 0.7197\n",
      "Epoch 11/100\n",
      "243s - loss: 1.4089 - acc: 0.6664 - val_loss: 1.1137 - val_acc: 0.7209\n",
      "Epoch 12/100\n",
      "244s - loss: 1.3686 - acc: 0.6708 - val_loss: 1.1129 - val_acc: 0.7247\n",
      "Epoch 13/100\n",
      "246s - loss: 1.4182 - acc: 0.6593 - val_loss: 1.1098 - val_acc: 0.7221\n",
      "Epoch 14/100\n",
      "246s - loss: 1.4245 - acc: 0.6541 - val_loss: 1.1109 - val_acc: 0.7235\n",
      "Epoch 15/100\n",
      "243s - loss: 1.4263 - acc: 0.6550 - val_loss: 1.1085 - val_acc: 0.7238\n",
      "Epoch 16/100\n",
      "270s - loss: 1.3915 - acc: 0.6606 - val_loss: 1.1058 - val_acc: 0.7203\n",
      "Epoch 17/100\n",
      "245s - loss: 1.4418 - acc: 0.6538 - val_loss: 1.1085 - val_acc: 0.7226\n",
      "Epoch 18/100\n",
      "244s - loss: 1.4113 - acc: 0.6651 - val_loss: 1.1110 - val_acc: 0.7265\n",
      "Epoch 19/100\n",
      "243s - loss: 1.4402 - acc: 0.6531 - val_loss: 1.1113 - val_acc: 0.7268\n",
      "Epoch 20/100\n",
      "240s - loss: 1.3861 - acc: 0.6711 - val_loss: 1.1118 - val_acc: 0.7224\n",
      "Epoch 21/100\n",
      "249s - loss: 1.4146 - acc: 0.6673 - val_loss: 1.1134 - val_acc: 0.7203\n",
      "Epoch 22/100\n",
      "240s - loss: 1.3748 - acc: 0.6712 - val_loss: 1.1148 - val_acc: 0.7265\n",
      "Epoch 23/100\n",
      "245s - loss: 1.4047 - acc: 0.6601 - val_loss: 1.1101 - val_acc: 0.7241\n",
      "Epoch 24/100\n",
      "243s - loss: 1.4282 - acc: 0.6528 - val_loss: 1.1113 - val_acc: 0.7229\n",
      "Epoch 25/100\n",
      "243s - loss: 1.4091 - acc: 0.6606 - val_loss: 1.1095 - val_acc: 0.7232\n",
      "Epoch 26/100\n",
      "272s - loss: 1.3992 - acc: 0.6610 - val_loss: 1.1041 - val_acc: 0.7209\n",
      "Epoch 27/100\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print 'Setting up'\n",
    "    setup('/home/afguerrerohernan/data/patients_processed/')\n",
    "    print 'Training completed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data = load_data('/home/afguerrerohernan/data/patients_processed/')\n",
    "# data, test = split_data(data)\n",
    "# model = train_model(data, k_folds=9, batch_size=192, epochs=1, lr=1e-5, decay=0.9, m=0.5, ridge=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_model(model, test, batch_size=192)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
