{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Flatten, Recurrent\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: p17\n",
      "Processing: p16\n",
      "Processing: p12\n",
      "Processing: p14\n",
      "Processing: p2\n",
      "Processing: p11\n",
      "Processing: p19\n",
      "Processing: p18\n",
      "Processing: p10\n",
      "Processing: p13\n",
      "Processing: p8\n",
      "Processing: p5\n",
      "Processing: p15\n",
      "Processing: p6\n",
      "Processing: p1\n",
      "Processing: p0\n",
      "Processing: p3\n",
      "Processing: p7\n",
      "Processing: p9\n",
      "Processing: p4\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data_dir = '/home/afguerrerohernan/data/patients_processed/'\n",
    "    data_dir_output = '/home/afguerrerohernan/data/patients_processed_2'\n",
    "    \n",
    "    optimizer = RMSprop(lr=1e-4, decay=0.8)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(\n",
    "        Conv1D(25, 50, padding='valid', trainable=False, input_shape=(15000, 3),\n",
    "               name='conv1d_1'))\n",
    "    model.add(BatchNormalization(name='batch_normalization_1', trainable=False))\n",
    "    model.add(LeakyReLU(alpha=0.3, name='leaky_re_lu_1', trainable=False))\n",
    "\n",
    "    model.add(Conv1D(25, 50, padding='valid', trainable=False, name='conv1d_2'))\n",
    "    model.add(BatchNormalization(name='batch_normalization_2', trainable=False))\n",
    "    model.add(LeakyReLU(alpha=0.3, name='leaky_re_lu_2', trainable=False))\n",
    "\n",
    "    model.add(Conv1D(25, 50, padding='valid', trainable=False, name='conv1d_3'))\n",
    "    model.add(BatchNormalization(name='batch_normalization_3', trainable=False))\n",
    "    model.add(LeakyReLU(alpha=0.3, name='leaky_re_lu_3', trainable=False))\n",
    "\n",
    "    model.add(Conv1D(25, 50, padding='valid', trainable=False, name='conv1d_4'))\n",
    "    model.add(BatchNormalization(name='batch_normalization_4', trainable=False))\n",
    "    model.add(LeakyReLU(alpha=0.3, name='leaky_re_lu_4', trainable=False))\n",
    "\n",
    "    model.add(Conv1D(25, 50, padding='valid', trainable=False, name='conv1d_5'))\n",
    "    model.add(BatchNormalization(name='batch_normalization_5', trainable=False))\n",
    "    model.add(LeakyReLU(alpha=0.3, name='leaky_re_lu_5', trainable=False))\n",
    "\n",
    "    model.add(MaxPooling1D(name='max_pooling1d_1', trainable=False))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.load_weights('/home/afguerrerohernan/work/DeepSleep/exp012/DS_f14-e100-lr0.0001-dcy0.8-m0.5-reg0.0002_001-0.90.h5', by_name=True)\n",
    "\n",
    "    for np_name in glob.glob(os.path.join(data_dir, '*.np[yz]')):\n",
    "        with np.load(np_name) as data:\n",
    "            print 'Processing: ' + os.path.splitext(os.path.basename(np_name))[0]\n",
    "            z = model.predict(data['X'], batch_size=196, verbose=2)\n",
    "            new_np_name = os.path.join(data_dir_output, os.path.basename(np_name))\n",
    "            np.savez(new_np_name, Z=z, Y=data['Y'], name=os.path.splitext(os.path.basename(np_name))[0])\n",
    "            \n",
    "    print 'Complete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2043, 7377, 25)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'X is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-458291e51f3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/afguerrerohernan/data/patients_processed_2/p1.npz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cm/shared/apps/cm-ml-pythondeps/lib64/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    235\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not a file in the archive\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'X is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "with np.load('/home/afguerrerohernan/data/patients_processed_2/p1.npz') as data:\n",
    "    print data['Z'].shape\n",
    "    print data['Y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
